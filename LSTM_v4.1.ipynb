{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_v4.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"luMjNtsqifzl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595004559113,"user_tz":360,"elapsed":4042,"user":{"displayName":"Tahjid Ashfaque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWExk8N_dmQ2sYtoL-X9a4oibOw4pZL-g3RDCVyg=s64","userId":"03393843294112175633"}},"outputId":"0856e2fa-cdb9-4877-8049-a2346b41de96"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from numpy import random\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from torch.utils.data import DataLoader\n","from collections import deque\n","import numpy as np\n","import multiprocessing\n","import time\n","from numpy import array\n","import pandas as pd\n","from torch.utils.data import TensorDataset, DataLoader\n","torch.manual_seed(1)\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"8y4Ls1vqi5dn","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import MinMaxScaler\n","#rotate a list by given offset, (negative offset, right to left) \n","def rotateList(items, offset):\n","    return np.roll(items,offset)\n","\n","def secondToMillisecond(val):\n","    return val*1000\n","\n","def gaussiantimeseries(limit = 60, interval = 2):\n","    data = {}\n","    for t in range(0,limit,interval):\n","        data[t]=random.normal(loc = random.uniform(1,100), scale =1.5, size =1000).astype(float)\n","    return data\n","\n","def createsignal(limit = 60, interval = 2):\n","    signal1, signal2, offset = [],[],[]\n","    limit = secondToMillisecond(limit)\n","    offset = random.randint(-10,10)\n","    data = gaussiantimeseries(limit, interval)\n","    for t in data:\n","        dist = data[t]\n","        signal1.append(random.choice(dist))\n","        signal2.append(random.choice(dist))\n","    return array(signal1).reshape((len(signal1), 1)), array(signal2).reshape((len(signal2), 1)), array(rotateList(signal2,offset)).reshape((len(signal2), 1)), offset\n","\n","def createsignals(num = 50, limit = 60, interval = 2, normalize = False):\n","    input_seq = []\n","    data = []\n","    for i in range(num):\n","        sig1, sig2original, sig2, offset = createsignal(limit = limit)\n","        data.append([sig1, sig2original, sig2, offset])\n","        train_data = np.hstack((sig1,sig2)).astype(float)\n","        #train data without normalization\n","        if not normalize:\n","            train_data = torch.FloatTensor(train_data)\n","            input_seq.append((train_data, torch.FloatTensor([offset])))\n","        else:\n","            scaler = MinMaxScaler(feature_range=(-1, 1))\n","            train_data_normalized = scaler.fit_transform(train_data)\n","            train_data_normalized = torch.FloatTensor(train_data_normalized)\n","            input_seq.append((train_data_normalized, torch.FloatTensor([offset])))\n","    return input_seq, data\n","\n","def createsignalsfortensor(num = 50, limit = 60, interval = 2, normalize = False):\n","    input_seq = []\n","    labels = []\n","    for i in range(num):\n","        sig1, sig2original, sig2, offset = createsignal(limit = limit)\n","        train_data = np.hstack((sig1,sig2)).astype(float)\n","        #train data without normalization\n","        if not normalize:\n","            train_data = torch.FloatTensor(train_data)\n","            input_seq.append(train_data)\n","            labels.append(torch.FloatTensor([offset]))\n","        else:\n","            scaler = MinMaxScaler(feature_range=(-1, 1))\n","            train_data_normalized = scaler.fit_transform(train_data)\n","            train_data_normalized = torch.FloatTensor(train_data_normalized)\n","            input_seq.append(train_data_normalized)\n","            labels.append(torch.FloatTensor([offset]))\n","    return input_seq, labels\n","# print(createsignal())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1GUBGQC9i-7N","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595006583064,"user_tz":360,"elapsed":304408,"user":{"displayName":"Tahjid Ashfaque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWExk8N_dmQ2sYtoL-X9a4oibOw4pZL-g3RDCVyg=s64","userId":"03393843294112175633"}}},"source":["train_input, train_label = createsignalsfortensor(num=1000, limit = 60, interval = 1, normalize = False)\n","test_input, test_label = createsignalsfortensor()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZXeyIbgI0Fsy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1595006866144,"user_tz":360,"elapsed":30242,"user":{"displayName":"Tahjid Ashfaque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWExk8N_dmQ2sYtoL-X9a4oibOw4pZL-g3RDCVyg=s64","userId":"03393843294112175633"}},"outputId":"57f1eef4-0cdd-457a-8f0f-4627e2af1115"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nywykOPfkbvq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594957565425,"user_tz":360,"elapsed":1853744,"user":{"displayName":"Tahjid Ashfaque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWExk8N_dmQ2sYtoL-X9a4oibOw4pZL-g3RDCVyg=s64","userId":"03393843294112175633"}},"outputId":"fbb720af-84cb-44a0-d162-729ee0a3eab2"},"source":["train_label[0].float().shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"Ez-beYT4mFs3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595007277459,"user_tz":360,"elapsed":878,"user":{"displayName":"Tahjid Ashfaque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWExk8N_dmQ2sYtoL-X9a4oibOw4pZL-g3RDCVyg=s64","userId":"03393843294112175633"}}},"source":["class CustomDataset(torch.utils.data.Dataset):\n","  def __init__(self, data, labels):\n","        self.labels = labels\n","        self.data = data\n","\n","  def __len__(self):\n","        return len(self.data)\n","\n","  def __getitem__(self, index):\n","        X = self.data[index]\n","        y = self.labels[index]\n","\n","        return X, y"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQa3b6DmkXH8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595007278302,"user_tz":360,"elapsed":583,"user":{"displayName":"Tahjid Ashfaque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWExk8N_dmQ2sYtoL-X9a4oibOw4pZL-g3RDCVyg=s64","userId":"03393843294112175633"}}},"source":["train_data = CustomDataset(train_input,train_label)\n","# val_data = CustomDataset(test_input,test_label)\n","test_data = CustomDataset(test_input,test_label)\n","\n","batch_size = 10\n","\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","# val_loader = DataLoader(val_data, shuffle=True, batch_size = batch_size)\n","test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"8bmYWFR1n8WW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595007280439,"user_tz":360,"elapsed":825,"user":{"displayName":"Tahjid Ashfaque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWExk8N_dmQ2sYtoL-X9a4oibOw4pZL-g3RDCVyg=s64","userId":"03393843294112175633"}}},"source":["class LSTM(nn.Module):\n","    def __init__(self, input_size=2, output_size = 1, hidden_dim = 512, n_layers = 2, drop_prob=0):\n","        super(LSTM, self).__init__()\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.hidden_dim = hidden_dim\n","        \n","\n","        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n","        self.dropout = nn.Dropout(drop_prob)\n","        self.fc = nn.Linear(hidden_dim, output_size)\n","        # self.sigmoid = nn.Sigmoid()\n","        \n","    def forward(self, x, hidden):\n","        batch_size = x.size(0)\n","        # x = x.long()\n","        lstm_out, hidden = self.lstm(x, hidden)\n","        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n","        \n","        # lstm_out = self.dropout(lstm_out)\n","        out = self.fc(lstm_out)\n","        # out = self.sigmoid(out)\n","        \n","        out = out.view(batch_size, -1)\n","        out = out[:,-1]\n","        # print(out.shape)\n","        return out, hidden\n","    \n","    def init_hidden(self, batch_size):\n","        # print(batch_size)\n","        weight = next(self.parameters()).data\n","        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n","                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n","        return hidden"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"I-3n62r_pcWM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595007292587,"user_tz":360,"elapsed":9026,"user":{"displayName":"Tahjid Ashfaque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWExk8N_dmQ2sYtoL-X9a4oibOw4pZL-g3RDCVyg=s64","userId":"03393843294112175633"}}},"source":["model = LSTM()\n","model.to(device)\n","\n","lr = 0.0001\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrf3QNZG6C_K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":697},"executionInfo":{"status":"ok","timestamp":1595021777403,"user_tz":360,"elapsed":14481506,"user":{"displayName":"Tahjid Ashfaque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWExk8N_dmQ2sYtoL-X9a4oibOw4pZL-g3RDCVyg=s64","userId":"03393843294112175633"}},"outputId":"43c688cb-dcb1-4a68-81a8-19dac28697f6"},"source":["epochs = 10\n","counter = 0\n","print_every = 100\n","clip = 5\n","valid_loss_min = np.Inf\n","\n","model.train()\n","for i in range(epochs):\n","    # print(batch_size)\n","    print(\"Epoch {}/{}\".format(i+1, epochs))\n","    print('-' * 20)\n","    epoch_loss = 0.0\n","    h = model.init_hidden(batch_size)\n","    model.zero_grad()\n","    for inputs, labels in train_loader:\n","        # print(inputs.shape)\n","        counter += 1\n","        h = tuple([e.data for e in h])\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        output, h = model(inputs, h)\n","        # print(\"a\",output.shape)\n","        # print(\"b\",labels.squeeze().shape)\n","        optimizer.zero_grad()\n","        loss = criterion(output, labels.squeeze())\n","        # print(output)\n","        # print(labels)\n","        # break\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        epoch_loss += output.shape[0] * loss.item()\n","        if counter%print_every == 0:\n","        #     # print(batch_size)\n","        #     val_h = model.init_hidden(batch_size)\n","        #     val_losses = []\n","        #     model.eval()\n","        #     for inp, lab in val_loader:\n","        #         val_h = tuple([each.data for each in val_h])\n","        #         inp, lab = inp.to(device), lab.to(device)\n","        #         out, val_h = model(inp, val_h)\n","        #         val_loss = criterion(out, lab.squeeze())\n","        #         val_losses.append(val_loss.item())\n","                \n","            # model.train()\n","            print(\"Epoch: {}/{}\".format(i+1, epochs),\n","                  \"Step: {}\".format(counter),\n","                  \"Loss: {:.6f}\".format(loss.item()))\n","            #       \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n","            # if np.mean(val_losses) <= valid_loss_min:\n","            #     # torch.save(model.state_dict(), './state_dict.pt')\n","            #     print('Validation loss decreased ({:.6f} --> {:.6f}).'.format(valid_loss_min,np.mean(val_losses)))\n","            #     valid_loss_min = np.mean(val_losses)\n","    # break\n","    print(\"Epoch {} Loss {}\".format(i+1, epoch_loss / len(train_input)))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","--------------------\n","Epoch: 1/10 Step: 100 Loss: 32.085953\n","Epoch 1 Loss 30.959558176994324\n","Epoch 2/10\n","--------------------\n","Epoch: 2/10 Step: 200 Loss: 23.286352\n","Epoch 2 Loss 29.79758045196533\n","Epoch 3/10\n","--------------------\n","Epoch: 3/10 Step: 300 Loss: 26.004011\n","Epoch 3 Loss 30.50064385890961\n","Epoch 4/10\n","--------------------\n","Epoch: 4/10 Step: 400 Loss: 12.052190\n","Epoch 4 Loss 26.51044460296631\n","Epoch 5/10\n","--------------------\n","Epoch: 5/10 Step: 500 Loss: 9.414104\n","Epoch 5 Loss 21.610776422023772\n","Epoch 6/10\n","--------------------\n","Epoch: 6/10 Step: 600 Loss: 9.048156\n","Epoch 6 Loss 17.328953034877777\n","Epoch 7/10\n","--------------------\n","Epoch: 7/10 Step: 700 Loss: 7.753678\n","Epoch 7 Loss 11.322938318252563\n","Epoch 8/10\n","--------------------\n","Epoch: 8/10 Step: 800 Loss: 7.070020\n","Epoch 8 Loss 15.853488286733628\n","Epoch 9/10\n","--------------------\n","Epoch: 9/10 Step: 900 Loss: 19.618713\n","Epoch 9 Loss 15.815981690883637\n","Epoch 10/10\n","--------------------\n","Epoch: 10/10 Step: 1000 Loss: 18.262135\n","Epoch 10 Loss 11.848270016908646\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TcGi6R6Uhuxt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1595021900963,"user_tz":360,"elapsed":34887,"user":{"displayName":"Tahjid Ashfaque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWExk8N_dmQ2sYtoL-X9a4oibOw4pZL-g3RDCVyg=s64","userId":"03393843294112175633"}},"outputId":"8eabcbbb-182c-4c99-eba9-2b079378c90b"},"source":["test_losses = []\n","num_correct = 0\n","h = model.init_hidden(batch_size)\n","\n","model.eval()\n","for inputs, labels in test_loader:\n","    h = tuple([each.data for each in h])\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    # print(inputs)\n","    output, h = model(inputs, h)\n","    print(f\"Offset {labels.squeeze().data}, Prediction {output.data}\")\n","    test_loss = criterion(output, labels.squeeze())\n","    test_losses.append(test_loss.item())\n","    pred = torch.round(output)  # Rounds the output to 0/1\n","    correct_tensor = pred.eq(labels.squeeze().view_as(pred))\n","    correct = np.squeeze(correct_tensor.cpu().numpy())\n","    num_correct += np.sum(correct)\n","\n","print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n","test_acc = num_correct/len(test_loader.dataset)\n","print(\"Test accuracy: {:.3f}%\".format(test_acc*100))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Offset tensor([ 5.,  4.,  9., -2., -3., -6.,  1.,  6., -6.,  3.], device='cuda:0'), Prediction tensor([ 4.3864,  5.3206,  5.6908, -4.9569, -4.9633, -5.2299, -5.0490,  5.5100,\n","        -5.3521, -4.9862], device='cuda:0')\n","Offset tensor([-5., -8.,  2., -3., -3.,  3., -7., -2., -5., -9.], device='cuda:0'), Prediction tensor([-4.9775, -5.0612,  1.0339, -4.8749, -4.8601, -5.1333, -5.3361, -4.7561,\n","        -5.1246, -5.1495], device='cuda:0')\n","Offset tensor([ 4.,  3., -6., -9., -4.,  6., -7.,  3.,  3.,  6.], device='cuda:0'), Prediction tensor([ 5.3132,  4.7652, -5.0822, -5.2572, -5.2212,  5.5428, -5.2080, -5.0136,\n","         5.5068,  6.0613], device='cuda:0')\n","Offset tensor([ 7., -1.,  2., -7.,  1.,  8.,  4., -8., -1.,  7.], device='cuda:0'), Prediction tensor([ 5.6267, -0.5515, -5.0087, -5.2725, -4.1911,  6.2118,  5.8392, -5.3134,\n","         0.0498,  5.3421], device='cuda:0')\n","Offset tensor([  8.,   6., -10.,   9.,   5.,  -9.,   9.,  -5.,  -9.,   9.],\n","       device='cuda:0'), Prediction tensor([ 5.7185,  5.9576, -5.1529,  5.0969,  5.7624, -5.2493,  4.6743, -5.3747,\n","        -5.1254,  5.7456], device='cuda:0')\n","Test loss: 10.643\n","Test accuracy: 16.000%\n"],"name":"stdout"}]}]}