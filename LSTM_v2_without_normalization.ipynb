{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_v2_without_normalization.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"IGd0UTtsAhrE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594669702949,"user_tz":360,"elapsed":1168,"user":{"displayName":"Tahjid Ashfaque Mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiATFk51SguXn70zJprd1GcXHxsI06mHHZBBMf=s64","userId":"04530508710412041120"}},"outputId":"aa9ff619-66ad-47cf-f847-17e1fae6c06e"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from numpy import random\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from torch.utils.data import DataLoader\n","from collections import deque\n","import numpy as np\n","import multiprocessing\n","import time\n","\n","torch.manual_seed(1)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ruZEvaXKArmD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594669704415,"user_tz":360,"elapsed":715,"user":{"displayName":"Tahjid Ashfaque Mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiATFk51SguXn70zJprd1GcXHxsI06mHHZBBMf=s64","userId":"04530508710412041120"}}},"source":["from sklearn.preprocessing import MinMaxScaler\n","#rotate a list by given offset, (negative offset, right to left) \n","def rotateList(items, offset):\n","    return np.roll(items,offset)\n","    \n","def gaussiantimeseries(limit = 60, interval = 2):\n","    data = {}\n","    for t in range(0,limit,interval):\n","        data[t]=random.normal(loc = random.uniform(1,100), scale =1.5, size =1000)\n","    return data\n","\n","def createsignal(limit = 60, interval = 2):\n","    signal1, signal2, offset = [],[],[]\n","    offset = random.randint(-5,5)\n","    data = gaussiantimeseries(limit, interval)\n","    for t in data:\n","        dist = data[t]\n","        signal1.append(random.choice(dist))\n","        signal2.append(random.choice(dist))\n","    return signal1, rotateList(signal2,offset), offset\n","\n","def createsignals(num = 50, limit = 60, interval = 2, normalize = False):\n","    input_seq = []\n","    for i in range(num):\n","        sig1, sig2, offset = createsignal(limit = limit)\n","        train_data = np.stack((sig1,sig2)).astype(float)\n","        #train data without normalization\n","        if not normalize:\n","            train_data = torch.FloatTensor(train_data.reshape(-1,1)).view(-1)\n","            input_seq.append((train_data, torch.FloatTensor([offset])))\n","        else:\n","            scaler = MinMaxScaler(feature_range=(-1, 1))\n","            train_data_normalized = scaler.fit_transform(train_data.reshape(-1, 1))\n","            train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1)\n","            input_seq.append((train_data_normalized, torch.FloatTensor([offset])))\n","    return input_seq\n","# print(createsignal())"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"m2OvQE37GDnm","colab_type":"code","colab":{}},"source":["class LSTM(nn.Module):\n","    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n","        super().__init__()\n","        self.hidden_layer_size = hidden_layer_size\n","\n","        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n","\n","        self.linear = nn.Linear(hidden_layer_size, output_size)\n","\n","        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n","                            torch.zeros(1,1,self.hidden_layer_size))\n","\n","    def forward(self, input_seq):\n","        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n","        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n","        return predictions[-1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rmNP3Trj9Itd","colab_type":"text"},"source":["Creating Data and training without normalization"]},{"cell_type":"code","metadata":{"id":"G0xsmkP5FLQ9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594669725914,"user_tz":360,"elapsed":18763,"user":{"displayName":"Tahjid Ashfaque Mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiATFk51SguXn70zJprd1GcXHxsI06mHHZBBMf=s64","userId":"04530508710412041120"}}},"source":["train_input = createsignals(num=10000, normalize = False)\n","test_input = createsignals()\n","# training_length = int(len(input)*(.8))\n","# train_input = input[:training_length]\n","# val_input = input[training_length:] "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"snuDJti5uRR_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1594669741323,"user_tz":360,"elapsed":636,"user":{"displayName":"Tahjid Ashfaque Mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiATFk51SguXn70zJprd1GcXHxsI06mHHZBBMf=s64","userId":"04530508710412041120"}},"outputId":"62f179a0-1eb7-42b9-d352-0fe5d538cf85"},"source":["train_input[:1]"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(tensor([ 39.3136,  39.9405,  46.9535,  48.5853,  50.3278,  66.2109,  32.0394,\n","           15.3345,  42.3119,  63.9890,  93.0358,  79.7846,  51.9152,  65.4746,\n","           30.5768,  34.5674,  91.6256,  34.1958,  10.8733,  33.3607,  99.5029,\n","           52.3128,  13.7111,  41.0224,  86.1746,  20.6475,   7.3225,  96.3329,\n","           10.5937,  72.1510, 100.0675,  11.3663,  70.0137,  42.3683,  40.6009,\n","           45.6989,  50.9479,  50.2993,  63.3569,  29.3851,  17.3014,  44.4835,\n","           62.6480,  89.9707,  80.9381,  52.2071,  62.9261,  33.6998,  33.2581,\n","           94.8048,  35.8998,  11.3545,  33.5116,  96.7467,  51.3826,  13.3649,\n","           40.3740,  85.9993,  16.4067,   6.4366]), tensor([3.]))]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"THKYR6wPGGtR","colab_type":"code","colab":{}},"source":["model = LSTM()\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oUJF_ZxEQ5Gp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b815a271-64ea-4be4-d40d-f8c3f7cce6cc"},"source":["epochs = 150\n","model.train()\n","for epoch in range(epochs):\n","    print(\"Epoch {}/{}\".format(epoch+1, epochs))\n","    print('-' * 10)\n","    epoch_loss = 0.0\n","    running_loss = 0.0\n","    model.zero_grad()\n","    for seq, labels in train_input:\n","\n","        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n","                        torch.zeros(1, 1, model.hidden_layer_size))\n","        # seq, labels = seq.to(device), labels.to(device)\n","        y_pred = model(seq)#.to(device)\n","        optimizer.zero_grad()\n","        loss = criterion(y_pred, labels)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += y_pred.shape[0] * loss.item()\n","\n","        # print statistics\n","        # running_loss += loss.item()\n","        # if i % 25 == 1:    \n","        #     print('[%d] loss: %.3f' %\n","        #           (i + 1, running_loss / 25))\n","        #     running_loss = 0.0\n","    print(\"Epoch {} Loss {}\".format(epoch+1, epoch_loss / len(train_input)))\n","\n","    # if i%25 == 1:\n","#     print(f'epoch: {i:3} loss: {loss.item():10.8f}')\n","\n","# print(f'epoch: {i:3} loss: {loss.item():10.10f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","----------\n","Epoch 1 Loss 8.265471697484703\n","Epoch 2/150\n","----------\n","Epoch 2 Loss 8.259073723232932\n","Epoch 3/150\n","----------\n","Epoch 3 Loss 8.256998374608903\n","Epoch 4/150\n","----------\n","Epoch 4 Loss 8.255725476868077\n","Epoch 5/150\n","----------\n","Epoch 5 Loss 8.254772655383125\n","Epoch 6/150\n","----------\n","Epoch 6 Loss 8.255879105000664\n","Epoch 7/150\n","----------\n","Epoch 7 Loss 8.25368494532602\n","Epoch 8/150\n","----------\n","Epoch 8 Loss 8.2524819595322\n","Epoch 9/150\n","----------\n","Epoch 9 Loss 8.251945942242862\n","Epoch 10/150\n","----------\n","Epoch 10 Loss 8.249477077814053\n","Epoch 11/150\n","----------\n","Epoch 11 Loss 8.250886402157104\n","Epoch 12/150\n","----------\n","Epoch 12 Loss 8.248389541610049\n","Epoch 13/150\n","----------\n","Epoch 13 Loss 8.247844660902237\n","Epoch 14/150\n","----------\n","Epoch 14 Loss 8.24627852370964\n","Epoch 15/150\n","----------\n","Epoch 15 Loss 8.242609364331674\n","Epoch 16/150\n","----------\n","Epoch 16 Loss 8.239161364138988\n","Epoch 17/150\n","----------\n","Epoch 17 Loss 8.232292557997297\n","Epoch 18/150\n","----------\n","Epoch 18 Loss 8.214286407992045\n","Epoch 19/150\n","----------\n","Epoch 19 Loss 8.219828999811492\n","Epoch 20/150\n","----------\n","Epoch 20 Loss 8.152729216584811\n","Epoch 21/150\n","----------\n","Epoch 21 Loss 8.1877163745783\n","Epoch 22/150\n","----------\n","Epoch 22 Loss 7.96978149161165\n","Epoch 23/150\n","----------\n","Epoch 23 Loss 7.564668225231479\n","Epoch 24/150\n","----------\n","Epoch 24 Loss 7.139603431986743\n","Epoch 25/150\n","----------\n","Epoch 25 Loss 6.749801820549384\n","Epoch 26/150\n","----------\n","Epoch 26 Loss 6.259096033705061\n","Epoch 27/150\n","----------\n","Epoch 27 Loss 5.659944174068801\n","Epoch 28/150\n","----------\n","Epoch 28 Loss 5.14104908293825\n","Epoch 29/150\n","----------\n","Epoch 29 Loss 4.5611750516251774\n","Epoch 30/150\n","----------\n","Epoch 30 Loss 4.328162686901809\n","Epoch 31/150\n","----------\n","Epoch 31 Loss 3.9171359296176784\n","Epoch 32/150\n","----------\n","Epoch 32 Loss 3.667821155388141\n","Epoch 33/150\n","----------\n","Epoch 33 Loss 3.3812730830542015\n","Epoch 34/150\n","----------\n","Epoch 34 Loss 3.2114536180635853\n","Epoch 35/150\n","----------\n","Epoch 35 Loss 2.9025170285365576\n","Epoch 36/150\n","----------\n","Epoch 36 Loss 2.7668267249371064\n","Epoch 37/150\n","----------\n","Epoch 37 Loss 2.6658220124705028\n","Epoch 38/150\n","----------\n","Epoch 38 Loss 2.6981503610588153\n","Epoch 39/150\n","----------\n","Epoch 39 Loss 2.254573090447936\n","Epoch 40/150\n","----------\n","Epoch 40 Loss 2.475287517626783\n","Epoch 41/150\n","----------\n","Epoch 41 Loss 2.9279778131387686\n","Epoch 42/150\n","----------\n","Epoch 42 Loss 2.629901299597689\n","Epoch 43/150\n","----------\n","Epoch 43 Loss 2.230005826910566\n","Epoch 44/150\n","----------\n","Epoch 44 Loss 1.8420191473011958\n","Epoch 45/150\n","----------\n","Epoch 45 Loss 2.0913198393457404\n","Epoch 46/150\n","----------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"blPNfDdi4bNh","colab_type":"code","colab":{}},"source":["epochs = 1\n","model.eval()\n","for epoch in range(epochs):\n","    print(\"Epoch {}/{}\".format(epoch+1, epochs))\n","    print('-' * 10)\n","    epoch_loss = 0.0\n","    running_loss = 0.0\n","    # model.zero_grad()\n","    for seq, labels in test_input:\n","\n","        # model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n","        #                 torch.zeros(1, 1, model.hidden_layer_size))\n","        # # seq, labels = seq.to(device), labels.to(device)\n","        y_pred = model(seq)#.to(device)\n","        print(f\"Offset {labels.data[0]}, Prediction {y_pred.data[0]}\")\n","        # optimizer.zero_grad()\n","        loss = criterion(y_pred, labels)\n","        # loss.backward()\n","        # optimizer.step()\n","        epoch_loss += y_pred.shape[0] * loss.item()\n","\n","        # print statistics\n","        # running_loss += loss.item()\n","        # if i % 25 == 1:    \n","        #     print('[%d] loss: %.3f' %\n","        #           (i + 1, running_loss / 25))\n","        #     running_loss = 0.0\n","    print(\"Epoch {} Loss {}\".format(epoch+1, epoch_loss / len(train_input)))\n","\n","    # if i%25 == 1:\n","#     pr"],"execution_count":null,"outputs":[]}]}